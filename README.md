# chatgptmemorytest
我说一个写论文的点子。 

首先，大家都知道chatgpt。chatgpt有一个特性是，它的对话长度是有限制的，这个限制不是厂商的商业决定，而是它使用的叫做transformer的技术本身有这么一个先天限制。

然后呢，有一个叫做autogpt的项目，它会让chatgpt不断的自动和自己对话，就像是自言自语的思考一样，不断的改善它的最终输出结果。因为chatgpt有长度限制，所以这个思考过程就被chatgpt的长度限制了。换个角度来说，对话长度的限制也可以理解为对它的记忆能力的限制，autogpt将不得不把chatgpt自动对话产生的内容尽量压缩到有限的字数中（一种比较拙劣的手法），被压缩的这部份就是被记住的，可以进入下一个思考循环，其余的就是被丢出记忆的。

因此对话长度看起来是一个很重要的特性。

然后有一个叫做chatrwkv的项目，它是诸多模仿chatgpt的开源项目之一，我可以在8G显存上运行它。这个项目有一个特点是，它没有使用transformer技术，因此它在理论上没有对话长度限制。它是在近期变得比较热门的，甚至相关论文都几乎没有。你可以在reddit上搜索下，关于它的性能的风评还可以的，认为它在同等资源条件下不弱于竞争者。

那么既然chatrwkv没有对话长度限制，如果把autogpt应用到chatrwkv上，chatrwkv是否真的能记住很早以前的对话，把它们纳入到当前的思考中呢？

那么我的点子就是对chatrwkv的记忆能力进行实验测试。

这个点子对于关注chatgpt的人来说是很难想到的，因为chatgpt有长度限制，其记忆能力在长度限制范围内的有效性也不会有人特意去质疑，想当然是有效的。而rwkv自己是一个相对较小的圈子（有一个原开发者的qq群），所以他们不一定有精力会想到这点。事实上关于rwkv的论文几乎没有，一方面因为原开发者不喜欢发论文，另一方面这是一个最近刚刚开始受到关注的项目，受关注的原因是他发布了一个14B参数量的英文模型，正是这个14B的模型的口碑很好。

下面我说下具体的实验办法，非常简单。用python脚本生成很多随机的名字，然后随机指定它们是一只猫或者一只狗，最后随机抽取其中一个名字，问AI这是不是一只狗。如此来生成一个任意长度的提问，来检查AI是否能再一个很长的对话跨度（记忆跨度）中抽取出正确的信息。

一个带有6个名字的提问范例是这样的：
I have 6 pets. Edeph is a dog. Ybtwd is a cat. Jmhcr is a cat. Oaaxo is a cat. Fdekr is a dog. Yukom is a cat.  Is Oaaxo a dog? Answer yes or no.

AI被要求按顺序读完这句话，记住每只宠物是狗或是猫，最后回答。以此来考验AI对上下文的记忆能力。

我在rwkv 3B模型上测试过，10个名字也无法正确回答。在rwkv 14B模型上测试，100个名字也可以正确回答。而测试1000个名字的时候，我的显存炸了。毕竟我只有8G显存。

我们还可以把猫狗提问替换成年龄提问，因为前者有50%的机率蒙对。名字的生成现在是随机的字母，如果换成从一个常用名字列表中抽取，或许AI的表现会更好，因为常用名AI在模型训练中见到的更多，所以它可能更擅长记住那些名字，就像人类也更擅长记忆熟悉的名字而不是乱序的字母。这些我们都可以添加进来，作为一种实验项目，或者你有更好的主意？

如果你读懂了我上面所说的话，你就知道，这个点子非常简单，需要的基础知识很少，所以任何有闲暇的人都可以联系我，考虑下合作？它或许会很重要，autogpt现在可是大热门。
这个实验的重要性应该会取决于实验结果，如果实验结果显示chatrwkv的记忆长度可以超出chatgpt，那么就会成为chatrwkv比chatgpt更适合搭配autogpt的一个证明。

